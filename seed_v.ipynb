{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR100, SVHN\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Import tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"raw_data/seed-v/merged_data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/seed-v\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset class for SEEDV and initialize a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEEDV(data.Dataset):\n",
    "    def __init__(self, emotion_dict: dict, num_subjects: int, data_path: str):\n",
    "        \"\"\"constructor for SEEDV dataset\n",
    "\n",
    "        Args:\n",
    "            emotion_dict (dict): dictionary of emotion_num as key and\n",
    "            emotion_str as value\n",
    "            num_subjects (int): number of subjects in the dataset\n",
    "            data_path (str): path to the directory containing npy data files\n",
    "        \"\"\"\n",
    "        self.emotion_dict = emotion_dict\n",
    "        self.num_subjects = num_subjects\n",
    "        self.data_path = data_path\n",
    "        self.tensor_dataset = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"load data from npy files to create tensor dataset\n",
    "\n",
    "        Returns:\n",
    "            data.TensorDataset: tensor dataset containing \n",
    "                all data from all npy files\n",
    "        \"\"\"\n",
    "        # initialize dataset and subjects to None at start\n",
    "        dataset = None\n",
    "        subjects = None\n",
    "\n",
    "        # loop through all files in the directory\n",
    "        for file in os.listdir(self.data_path):\n",
    "            # get the file path of the file\n",
    "            file_path = os.path.join(self.data_path, file)\n",
    "\n",
    "            # get subject number from the filename\n",
    "            s_num = np.int64(re.findall(\"\\d+\", file)[0]) - 1\n",
    "\n",
    "            # if dataset has not been created yet\n",
    "            if dataset is None:\n",
    "                # create subject meta labels for each sample in dataset\n",
    "                for i in range(len(np.load(file_path))):\n",
    "                    if subjects is None:\n",
    "                        subjects = s_num\n",
    "                    else:\n",
    "                        # need to hstack subjects to match tensor shapes of emotion\n",
    "                        subjects = np.hstack((subjects, s_num))\n",
    "                # load the data from the npy file\n",
    "                dataset = np.load(file_path)\n",
    "            # else if dataset already exists\n",
    "            else:\n",
    "                for i in range(len(np.load(file_path))):\n",
    "                    # hstack subjects to match tensor shapes of emotion\n",
    "                    subjects = np.hstack((subjects, s_num))\n",
    "                # stack the data vertically\n",
    "                dataset = np.vstack((dataset, np.load(file_path)))\n",
    "\n",
    "        # create tensor dataset with subject meta labels, features, and emotion labels\n",
    "        tensor_dataset = data.TensorDataset(torch.from_numpy(\n",
    "            subjects), torch.from_numpy(dataset[:, :-1]), torch.from_numpy(dataset[:, -1]))\n",
    "\n",
    "        return tensor_dataset\n",
    "\n",
    "    def get_subjects_data(self, s_nums: list):\n",
    "        \"\"\"get data for only subjects in s_nums\n",
    "\n",
    "        Args:\n",
    "            s_nums (list): list of subject numbers that identifies subjects\n",
    "\n",
    "        Returns:\n",
    "            tuple of torch.tensor: all features and all emotion numbers for only\n",
    "            specified subjects\n",
    "        \"\"\"\n",
    "        all_features = None\n",
    "        all_emotions = None\n",
    "\n",
    "        for s_num in s_nums:\n",
    "            if all_features == None:\n",
    "                all_features, all_emotions = self.__getitem__(s_num)\n",
    "            else:\n",
    "                features, targets = self.__getitem__(s_num)\n",
    "                all_features = torch.vstack((all_features, features))\n",
    "                all_emotions = torch.vstack((all_emotions, targets))\n",
    "\n",
    "        return all_features, all_emotions.reshape((1,-1))[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"get number of samples in dataset\n",
    "\n",
    "        Returns:\n",
    "            int: number of samples in dataset\n",
    "        \"\"\"\n",
    "        return len(self.tensor_dataset)\n",
    "\n",
    "    def __getitem__(self, s_num: int):\n",
    "        \"\"\"get data for a given s_num\n",
    "\n",
    "        Args:\n",
    "            s_num (int): number that identifies a subject\n",
    "\n",
    "        Returns:\n",
    "            tuple of torch.tensor: features and corresponding emotion numbers\n",
    "        \"\"\"\n",
    "        indices = torch.where(self.tensor_dataset[:][0] == s_num, True, False)\n",
    "        features = self.tensor_dataset[indices][1]\n",
    "        emotion_num = self.tensor_dataset[indices][2]\n",
    "\n",
    "        return features, emotion_num.to(torch.int64).reshape((1,-1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_v = SEEDV(emotion_dict = {0: 'disgust', 1: 'fear', 2: 'sad', 3: 'neutral', 4: 'happy'}, num_subjects=16, data_path=DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a train-val-test split by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaclasses = torch.randperm(16) # random permutation of subjects 0 to 15 which are the metaclasses\n",
    "train_metaclasses, val_metaclasses, test_metaclasses = metaclasses[0:12], metaclasses[12:14], metaclasses[14:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(data.Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        \"\"\"constructor for EEGDataset\"\"\"\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"get item by index\"\"\"\n",
    "        features, targets = self.features[idx], self.targets[idx]\n",
    "\n",
    "        return features, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"get number of samples in dataset\"\"\"\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = EEGDataset(*seed_v.get_subjects_data(train_metaclasses))\n",
    "val_set = EEGDataset(*seed_v.get_subjects_data(val_metaclasses))\n",
    "test_set = EEGDataset(*seed_v.get_subjects_data(test_metaclasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21876])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.targets.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataloaders and samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotBatchSampler(object):\n",
    "\n",
    "    def __init__(self, dataset_targets, N_way, K_shot, include_query=False, shuffle=True, shuffle_once=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            dataset_targets - PyTorch tensor of the labels of the data elements.\n",
    "            N_way - Number of classes to sample per batch.\n",
    "            K_shot - Number of examples to sample per class in the batch.\n",
    "            include_query - If True, returns batch of size N_way*K_shot*2, which \n",
    "                            can be split into support and query set. Simplifies\n",
    "                            the implementation of sampling the same classes but \n",
    "                            distinct examples for support and query set.\n",
    "            shuffle - If True, examples and classes are newly shuffled in each\n",
    "                      iteration (for training)\n",
    "            shuffle_once - If True, examples and classes are shuffled once in \n",
    "                           the beginning, but kept constant across iterations \n",
    "                           (for validation)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataset_targets = dataset_targets\n",
    "        self.N_way = N_way\n",
    "        self.K_shot = K_shot\n",
    "        self.shuffle = shuffle\n",
    "        self.include_query = include_query\n",
    "        if self.include_query:\n",
    "            self.K_shot *= 2\n",
    "        self.batch_size = self.N_way * self.K_shot  # Number of overall images per batch\n",
    "\n",
    "        # Organize examples by class\n",
    "        self.classes = torch.unique(self.dataset_targets).tolist()\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.indices_per_class = {}\n",
    "        self.batches_per_class = {}  # Number of K-shot batches that each class can provide\n",
    "        for c in self.classes:\n",
    "            self.indices_per_class[c] = torch.where(self.dataset_targets == c)[0]\n",
    "            self.batches_per_class[c] = self.indices_per_class[c].shape[0] // self.K_shot\n",
    "        # Create a list of classes from which we select the N classes per batch\n",
    "        self.iterations = sum(self.batches_per_class.values()) // self.N_way\n",
    "        # self.class_list = [c for c in self.classes for _ in range(self.batches_per_class[c])]\n",
    "        if shuffle_once or self.shuffle:\n",
    "            self.shuffle_data()\n",
    "        else:\n",
    "            # For testing, we iterate over classes instead of shuffling them\n",
    "            sort_idxs = [i+p*self.num_classes for i,\n",
    "                         c in enumerate(self.classes) for p in range(self.batches_per_class[c])]\n",
    "            # self.class_list = np.array(self.class_list)[np.argsort(sort_idxs)].tolist()\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        # Shuffle the examples per class\n",
    "        for c in self.classes:\n",
    "            perm = torch.randperm(self.indices_per_class[c].shape[0])\n",
    "            self.indices_per_class[c] = self.indices_per_class[c][perm]\n",
    "        # Shuffle the class list from which we sample. Note that this way of shuffling\n",
    "        # does not prevent to choose the same class twice in a batch. However, for \n",
    "        # training and validation, this is not a problem.\n",
    "        # random.shuffle(self.class_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffle data\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "\n",
    "        # Sample few-shot batches\n",
    "        start_index = defaultdict(int)\n",
    "        for it in range(self.iterations):\n",
    "            # Select N classes for the batch\n",
    "            # class_batch = self.class_list[it*self.N_way:(it+1)*self.N_way]  #\n",
    "            \n",
    "            # WARNING: Possible problem with this is that the last batch might\n",
    "            # not have all N classes\n",
    "            class_batch = random.sample(self.classes, self.N_way)\n",
    "            index_batch = []\n",
    "            for c in class_batch:  # For each class, select the next K examples and add them to the batch\n",
    "                index_batch.extend(self.indices_per_class[c][start_index[c]:start_index[c]+self.K_shot])\n",
    "                start_index[c] += self.K_shot\n",
    "                try:\n",
    "                    self.indices_per_class[c][start_index[c]]\n",
    "                except:\n",
    "                    start_index[c] = 0\n",
    "            if self.include_query:  # If we return support+query set, sort them so that they are easy to split\n",
    "                index_batch = index_batch[::2] + index_batch[1::2]\n",
    "            yield index_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 5\n",
    "K_SHOT = 10\n",
    "train_data_loader = data.DataLoader(train_set,\n",
    "                                    batch_sampler=FewShotBatchSampler(train_set.targets,\n",
    "                                                                      include_query=True,\n",
    "                                                                      N_way=N_WAY,\n",
    "                                                                      K_shot=K_SHOT,\n",
    "                                                                      shuffle=True),\n",
    "                                    num_workers=32)\n",
    "val_data_loader = data.DataLoader(val_set,\n",
    "                                  batch_sampler=FewShotBatchSampler(val_set.targets,\n",
    "                                                                    include_query=True,\n",
    "                                                                    N_way=N_WAY,\n",
    "                                                                    K_shot=K_SHOT,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    shuffle_once=True),\n",
    "                                  num_workers=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split batch into query and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_query_support(features, targets):\n",
    "    support_features, query_features = features.chunk(2, dim=0)\n",
    "    support_targets, query_targets = targets.chunk(2, dim=0)\n",
    "    return support_features, query_features, support_targets, query_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = next(iter(val_data_loader))\n",
    "support_features, query_features, support_targets, query_targets = split_query_support(features, targets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize and visualize the features in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "support_features = support_features / support_features.max(0, keepdim=True)[0]\n",
    "query_features = query_features / query_features.max(0, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "support_pca = pca.fit_transform(support_features)\n",
    "query_pca = pca.fit_transform(query_features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "ax[0].scatter(support_pca[:,0], support_pca[:,1], c=support_targets.reshape((-1,1)))\n",
    "ax[0].set_title(\"Support set\")\n",
    "ax[0].axis('off')\n",
    "ax[1].scatter(query_pca[:,0], query_pca[:,1], c=query_targets.reshape((-1,1)))\n",
    "ax[1].set_title(\"Query set\")\n",
    "ax[1].axis('off')\n",
    "plt.suptitle(\"Few Shot Batch\", weight='bold')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DCCA neural network used in SEEDV paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CCA methods and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca_metric_derivative(H1, H2):\n",
    "    r1 = 1e-3\n",
    "    r2 = 1e-3\n",
    "    eps = 1e-9\n",
    "    # transform the matrix: to be consistent with the original paper\n",
    "    H1 = H1.T\n",
    "    H2 = H2.T\n",
    "    # o1 and o2 are feature dimensions\n",
    "    # m is sample number\n",
    "    o1 = o2 = H1.shape[0]\n",
    "    m = H1.shape[1]\n",
    "\n",
    "    # calculate parameters\n",
    "    H1bar = H1 - H1.mean(axis=1).reshape([-1,1])\n",
    "    H2bar = H2 - H2.mean(axis=1).reshape([-1,1])\n",
    "\n",
    "    SigmaHat12 = (1.0 / (m - 1)) * np.matmul(H1bar, H2bar.T)\n",
    "    SigmaHat11 = (1.0 / (m - 1)) * np.matmul(H1bar, H1bar.T) + r1 * np.eye(o1)\n",
    "    SigmaHat22 = (1.0 / (m - 1)) * np.matmul(H2bar, H2bar.T) + r2 * np.eye(o2)\n",
    "\n",
    "    # eigenvalue and eigenvector decomposition\n",
    "    [D1, V1] = np.linalg.eigh(SigmaHat11)\n",
    "    [D2, V2] = np.linalg.eigh(SigmaHat22)\n",
    "\n",
    "    # remove eighvalues and eigenvectors smaller than 0\n",
    "    posInd1 = np.where(D1 > 0)[0]\n",
    "    D1 = D1[posInd1]\n",
    "    V1 = V1[:, posInd1]\n",
    "\n",
    "    posInd2 = np.where(D2 > 0)[0]\n",
    "    D2 = D2[posInd2]\n",
    "    V2 = V2[:, posInd2]\n",
    "\n",
    "    # calculate matrxi T\n",
    "    SigmaHat11RootInv = np.matmul(np.matmul(V1, np.diag(D1 ** -0.5)), V1.T)\n",
    "    SigmaHat22RootInv = np.matmul(np.matmul(V2, np.diag(D2 ** -0.5)), V2.T)\n",
    "    Tval = np.matmul(np.matmul(SigmaHat11RootInv,SigmaHat12), SigmaHat22RootInv)\n",
    "    # By default, we will use all the singular values\n",
    "    tmp = np.matmul(Tval.T, Tval)\n",
    "    corr = np.sqrt(np.trace(tmp))\n",
    "    cca_loss = -1 * corr\n",
    "\n",
    "    # calculate the derivative of H1 and H2\n",
    "    U_t, D_t, V_prime_t = np.linalg.svd(Tval)\n",
    "    Delta12 = SigmaHat11RootInv @ U_t @ V_prime_t @ SigmaHat22RootInv\n",
    "    Delta11 = SigmaHat11RootInv @ U_t @ np.diag(D_t) @ U_t.T @ SigmaHat11RootInv\n",
    "    Delta22 = SigmaHat22RootInv @ U_t @ np.diag(D_t) @ U_t.T @ SigmaHat22RootInv\n",
    "    Delta11 = -0.5 * Delta11\n",
    "    Delta22 = -0.5 * Delta22\n",
    "\n",
    "    DerivativeH1 = ( 1.0 / (m - 1)) * (2 * (Delta11 @ H1bar) + Delta12 @ H2bar)\n",
    "    DerivativeH2 = ( 1.0 / (m - 1)) * (2 * (Delta22 @ H2bar) + Delta12 @ H1bar)\n",
    "\n",
    "    return cca_loss, DerivativeH1.T, DerivativeH2.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DCCA network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformLayers(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        super(TransformLayers, self).__init__()\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        for l_id in range(len(layer_sizes) - 1):\n",
    "            if l_id == len(layer_sizes) - 2:\n",
    "                layers.append(nn.Sequential(\n",
    "                    #nn.BatchNorm1d(num_features=layer_sizes[l_id], affine=False),\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id+1]),\n",
    "                    ))\n",
    "            else:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id+1]),\n",
    "                    nn.Sigmoid(),\n",
    "                    #nn.BatchNorm1d(num_features=layer_sizes[l_id+1], affine=False),\n",
    "                    ))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(AttentionFusion, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention_weights = nn.Parameter(torch.randn(self.output_dim, requires_grad=True))\n",
    "    def forward(self, x1, x2):\n",
    "        # calculate weigths for all input samples\n",
    "        row, _ = x1.shape\n",
    "        fused_tensor = torch.empty_like(x1)\n",
    "        alpha = []\n",
    "        for i in range(row):\n",
    "            tmp1 = torch.dot(x1[i,:], self.attention_weights)\n",
    "            tmp2 = torch.dot(x2[i,:], self.attention_weights)\n",
    "            alpha_1 = torch.exp(tmp1) / (torch.exp(tmp1) + torch.exp(tmp2))\n",
    "            alpha_2 = 1 - alpha_1\n",
    "            alpha.append((alpha_1.detach().cpu().numpy(), alpha_2.detach().cpu().numpy()))\n",
    "            fused_tensor[i, :] = alpha_1 * x1[i,:] + alpha_2 * x2[i, :]\n",
    "        return fused_tensor, alpha\n",
    "\n",
    "class DCCA_AM(nn.Module):\n",
    "    def __init__(self, input_size1, input_size2, layer_sizes1, layer_sizes2, outdim_size, categories, device):\n",
    "        super(DCCA_AM, self).__init__()\n",
    "        self.input_dim_split = input_size1\n",
    "        self.outdim_size = outdim_size\n",
    "        self.categories = categories\n",
    "        # self.use_all_singular_values = use_all_singular_values\n",
    "        self.device = device\n",
    "\n",
    "        self.model1 = TransformLayers(input_size1, layer_sizes1).to(self.device)\n",
    "        self.model2 = TransformLayers(input_size2, layer_sizes2).to(self.device)\n",
    "\n",
    "        # convert generator object to list for deepcopy(model) to work\n",
    "        self.model1_parameters = list(self.model1.parameters()) \n",
    "        self.model2_parameters = list(self.model2.parameters())\n",
    "\n",
    "        self.classification = nn.Linear(self.outdim_size, self.categories)\n",
    "\n",
    "        self.attention_fusion = AttentionFusion(outdim_size)\n",
    "    def forward(self, x):\n",
    "        x1 = x[:, :self.input_dim_split]\n",
    "        x2 = x[:, self.input_dim_split:]\n",
    "        # forward process: returns negative of cca loss and predicted labels\n",
    "        output1 = self.model1(x1)\n",
    "        output2 = self.model2(x2)\n",
    "        # cca_loss_val = self.loss(output1, output2)\n",
    "        cca_loss, partial_h1, partial_h2 = cca_metric_derivative(output1.detach().cpu().numpy(), output2.detach().cpu().numpy())\n",
    "        fused_tensor, alpha = self.attention_fusion(output1, output2)\n",
    "        out = self.classification(fused_tensor)\n",
    "        return out, cca_loss, output1, output2, partial_h1, partial_h2, fused_tensor.detach().cpu().data, alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define meta learning model and methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define baseline ProtoNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr, model_args):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            proto_dim - Dimensionality of prototype feature space\n",
    "            lr - Learning rate of Adam optimizer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, \\\n",
    "            output_dim, num_emotions, device = model_args\n",
    "        self.model = DCCA_AM(eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, output_dim, num_emotions, device).to(device)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[140, 180], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_prototypes(features, targets):\n",
    "        # Given a stack of features vectors and labels, return class prototypes\n",
    "        # features - shape [N, proto_dim], targets - shape [N]\n",
    "        features = features[0]\n",
    "        # targets = targets.reshape((1,-1))[0] \n",
    "        # already RESHAPED EARLIER in dataset_from_labels call\n",
    "        classes, _ = torch.unique(targets).sort() # Determine which classes we have\n",
    "        prototypes = []\n",
    "        # print(\"targets:\", targets)\n",
    "        for c in classes:\n",
    "            # print(\"c:\", c)\n",
    "            # print(features[torch.where(targets == c)[0]])\n",
    "            # maybe use for target in targets loop\n",
    "            p = features[torch.where(targets == c)[0]].mean(dim=0)  # Average class feature vectors\n",
    "            prototypes.append(p)\n",
    "        prototypes = torch.stack(prototypes, dim=0)\n",
    "        # Return the 'classes' tensor to know which prototype belongs to which class\n",
    "        return prototypes, classes\n",
    "\n",
    "    def classify_feats(self, prototypes, classes, feats, targets):\n",
    "        # Classify new examples with prototypes and return classification error\n",
    "        dist = torch.pow(prototypes[None, :] - feats[:, None], 2).sum(dim=2)  # Squared euclidean distance\n",
    "        preds = F.log_softmax(-dist, dim=1)\n",
    "        labels = (classes[None, :] == targets[:, None]).long().argmax(dim=-1)\n",
    "        acc = (preds.argmax(dim=1) == labels).float().mean()\n",
    "        return preds, labels, acc\n",
    "\n",
    "    def calculate_loss(self, batch, mode):\n",
    "        # Determine training loss for a given support and query set \n",
    "        features, targets = batch\n",
    "        outputs = self.model(features)  # Encode all images of support and query set\n",
    "        support_feats, query_feats, support_targets, query_targets = split_query_support(outputs, targets)\n",
    "        prototypes, classes = ProtoNet.calculate_prototypes(support_feats, support_targets)\n",
    "        preds, labels, acc = self.classify_feats(prototypes, classes, query_feats, query_targets)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        self.log(f\"{mode}_loss\", loss)\n",
    "        self.log(f\"{mode}_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.calculate_loss(batch, mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self.calculate_loss(batch, mode=\"val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ProtoMAML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoMAML(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, lr, lr_inner, lr_output, num_inner_steps, model_args):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            eeg_input_dim - Dimensionality of prototype feature space\n",
    "            lr - Learning rate of the outer loop Adam optimizer\n",
    "            lr_inner - Learning rate of th``e inner loop SGD optimizer\n",
    "            lr_output - Learning rate for the output layer in the inner loop\n",
    "            num_inner_steps - Number of inner loop updates to perform\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, \\\n",
    "            output_dim, num_emotions, device = model_args\n",
    "        self.model = DCCA_AM(eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, output_dim, num_emotions, device).to(device)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[140,180], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "    def run_model(self, local_model, output_weight, output_bias, features, labels):\n",
    "        # Execute a model with given output layer weights and inputs\n",
    "        dcca_out = local_model(features)\n",
    "        out = dcca_out[0]\n",
    "        cca_loss = dcca_out[1]\n",
    "        # get only first element of tuple in feats\n",
    "        preds = F.linear(out, output_weight, output_bias)\n",
    "        # loss = F.cross_entropy(preds, labels.reshape((-1,1))[0]) \n",
    "        # already RESHAPED EARLIER in dataset_from_labels calls\n",
    "        loss = 0.7 * cca_loss + 1.0 * F.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=1) == labels).float()\n",
    "        return loss, preds, acc\n",
    "        \n",
    "    def adapt_few_shot(self, support_features, support_targets):\n",
    "        # Determine prototype initialization\n",
    "        support_preds = self.model(support_features)\n",
    "        prototypes, classes = ProtoNet.calculate_prototypes(support_preds, support_targets)\n",
    "        support_labels = (classes[None,:] == support_targets[:,None]).long().argmax(dim=-1)\n",
    "        # Create inner-loop model and optimizer\n",
    "        local_model = deepcopy(self.model)\n",
    "        local_model.train()\n",
    "        local_optim = optim.SGD(local_model.parameters(), lr=self.hparams.lr_inner)\n",
    "        local_optim.zero_grad()\n",
    "        # Create output layer weights with prototype-based initialization\n",
    "        init_weight = 2 * prototypes\n",
    "        init_bias = -torch.norm(prototypes, dim=1)**2\n",
    "        output_weight = init_weight.detach().requires_grad_()\n",
    "        output_bias = init_bias.detach().requires_grad_()\n",
    "        \n",
    "        # Optimize inner loop model on support set\n",
    "        for _ in range(self.hparams.num_inner_steps):\n",
    "            # Determine loss on the support set\n",
    "            # print(support_labels)\n",
    "            loss, _, _ = self.run_model(local_model, output_weight, output_bias, support_features, support_labels)\n",
    "            # Calculate gradients and perform inner loop update\n",
    "            loss.backward()\n",
    "            local_optim.step()\n",
    "            # Update output layer via SGD\n",
    "            output_weight.data -= self.hparams.lr_output * output_weight.grad\n",
    "            output_bias.data -= self.hparams.lr_output * output_bias.grad\n",
    "            # Reset gradients\n",
    "            local_optim.zero_grad()\n",
    "            output_weight.grad.fill_(0)\n",
    "            output_bias.grad.fill_(0)\n",
    "            \n",
    "        # Re-attach computation graph of prototypes\n",
    "        output_weight = (output_weight - init_weight).detach() + init_weight\n",
    "        output_bias = (output_bias - init_bias).detach() + init_bias\n",
    "        \n",
    "        return local_model, output_weight, output_bias, classes\n",
    "        \n",
    "    def outer_loop(self, batch, mode=\"train\"):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Determine gradients for batch of tasks\n",
    "        for task_batch in batch:\n",
    "            features, targets = task_batch\n",
    "            support_features, query_features, support_targets, query_targets = split_query_support(features, targets)\n",
    "            # Perform inner loop adaptation\n",
    "            # print(support_targets)\n",
    "            local_model, output_weight, output_bias, classes = self.adapt_few_shot(support_features, support_targets)\n",
    "            # Determine loss of query set\n",
    "            query_labels = (classes[None,:] == query_targets[:,None]).long().argmax(dim=-1)\n",
    "            loss, preds, acc = self.run_model(local_model, output_weight, output_bias, query_features, query_labels)\n",
    "            # Calculate gradients for query set loss\n",
    "            if mode == \"train\":\n",
    "                loss.backward()\n",
    "\n",
    "                for p_global, p_local in zip(self.model.parameters(), local_model.parameters()):\n",
    "                    p_global.grad += p_local.grad  # First-order approx. -> add gradients of finetuned and base model\n",
    "            \n",
    "            accuracies.append(acc.mean().detach())\n",
    "            losses.append(loss.detach())\n",
    "        \n",
    "        # Perform update of base model\n",
    "        if mode == \"train\":\n",
    "            opt = self.optimizers()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        self.log(f\"{mode}_loss\", sum(losses) / len(losses))\n",
    "        self.log(f\"{mode}_acc\", sum(accuracies) / len(accuracies))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.outer_loop(batch, mode=\"train\")\n",
    "        return None  # Returning None means we skip the default training optimizer steps by PyTorch Lightning\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Validation requires to finetune a model, hence we need to enable gradients\n",
    "        torch.set_grad_enabled(True)\n",
    "        self.outer_loop(batch, mode=\"val\")\n",
    "        torch.set_grad_enabled(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define task batch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskBatchSampler(object):\n",
    "    \n",
    "    def __init__(self, dataset_targets, batch_size, N_way, K_shot, include_query=False, shuffle=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            dataset_targets - PyTorch tensor of the labels of the data elements.\n",
    "            batch_size - Number of tasks to aggregate in a batch\n",
    "            N_way - Number of classes to sample per batch.\n",
    "            K_shot - Number of examples to sample per class in the batch.\n",
    "            include_query - If True, returns batch of size N_way*K_shot*2, which \n",
    "                            can be split into support and query set. Simplifies\n",
    "                            the implementation of sampling the same classes but \n",
    "                            distinct examples for support and query set.\n",
    "            shuffle - If True, examples and classes are newly shuffled in each\n",
    "                      iteration (for training)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.batch_sampler = FewShotBatchSampler(dataset_targets, N_way, K_shot, include_query, shuffle)\n",
    "        self.task_batch_size = batch_size\n",
    "        self.local_batch_size = self.batch_sampler.batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Aggregate multiple batches before returning the indices\n",
    "        batch_list = []\n",
    "        for batch_idx, batch in enumerate(self.batch_sampler):\n",
    "            batch_list.extend(batch)\n",
    "            if (batch_idx+1) % self.task_batch_size == 0:\n",
    "                yield batch_list\n",
    "                batch_list = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)//self.task_batch_size\n",
    "    \n",
    "    def get_collate_fn(self):\n",
    "        # Returns a collate function that converts one big tensor into a list of task-specific tensors\n",
    "        def collate_fn(item_list):\n",
    "            features = torch.stack([feat for feat, target in item_list], dim=0)\n",
    "            targets = torch.stack([target for feat, target in item_list], dim=0)\n",
    "            features = features.chunk(self.task_batch_size, dim=0)\n",
    "            targets = targets.chunk(self.task_batch_size, dim=0)\n",
    "            return list(zip(features, targets))\n",
    "        return collate_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model training and testing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_loader, val_loader, **kwargs):\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, model_class.__name__),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=50,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\", every_n_epochs=1),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         enable_progress_bar=False,\n",
    "                         log_every_n_steps=12)\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(\n",
    "        CHECKPOINT_PATH, model_class.__name__ + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = model_class.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = model_class(**kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = model_class.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path)  # Load best checkpoint after training\n",
    "\n",
    "    return model\n",
    "\n",
    "def test_protomaml(model, dataset, k_shot=4):\n",
    "    pl.seed_everything(42)\n",
    "    model = model.to(device)\n",
    "    num_classes = dataset.targets.unique().shape[0]\n",
    "    exmps_per_class = dataset.targets.shape[0]//num_classes\n",
    "    \n",
    "    # Data loader for full test set as query set\n",
    "    full_dataloader = data.DataLoader(dataset, \n",
    "                                      batch_size=128, \n",
    "                                      num_workers=32, \n",
    "                                      shuffle=False, \n",
    "                                      drop_last=False)\n",
    "    # Data loader for sampling support sets\n",
    "    sampler = FewShotBatchSampler(dataset.targets, \n",
    "                                  include_query=False,\n",
    "                                  N_way=num_classes,\n",
    "                                  K_shot=k_shot,\n",
    "                                  shuffle=False,\n",
    "                                  shuffle_once=False)\n",
    "    sample_dataloader = data.DataLoader(dataset, \n",
    "                                        batch_sampler=sampler,\n",
    "                                        num_workers=32)\n",
    "    \n",
    "    # We iterate through the full dataset in two manners. First, to select the k-shot batch. \n",
    "    # Second, the evaluate the model on all other examples\n",
    "    accuracies = []\n",
    "    for (support_features, support_targets), support_indices in tqdm(zip(sample_dataloader, sampler), \"Performing few-shot finetuning\"):\n",
    "        support_features = support_features.to(device)\n",
    "        support_targets = support_targets.to(device)\n",
    "        try:\n",
    "            # Finetune new model on support set\n",
    "            local_model, output_weight, output_bias, classes = model.adapt_few_shot(support_features, support_targets)\n",
    "            with torch.no_grad():  # No gradients for query set needed\n",
    "                local_model.eval()\n",
    "                batch_acc = torch.zeros((0,), dtype=torch.float32, device=device)\n",
    "                # Evaluate all examples in test dataset\n",
    "                for query_features, query_targets in full_dataloader:\n",
    "                    query_features = query_features.to(device)\n",
    "                    query_targets = query_targets.to(device)\n",
    "                    query_labels = (classes[None,:] == query_targets[:,None]).long().argmax(dim=-1)\n",
    "                    _, _, acc = model.run_model(local_model, output_weight, output_bias, query_features, query_labels)\n",
    "                    batch_acc = torch.cat([batch_acc, acc.detach()], dim=0)\n",
    "                # Exclude support set elements\n",
    "                for s_idx in support_indices:\n",
    "                    batch_acc[s_idx] = 0\n",
    "                batch_acc = batch_acc.sum().item() / (batch_acc.shape[0] - len(support_indices))\n",
    "                accuracies.append(batch_acc)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print(\"NaN layer encountered\")\n",
    "    return mean(accuracies), stdev(accuracies)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constant (same as for ProtoNet)\n",
    "N_WAY = 5\n",
    "K_SHOT = 10\n",
    "\n",
    "# Training set\n",
    "train_protomaml_sampler = TaskBatchSampler(train_set.targets, \n",
    "                                           include_query=True,\n",
    "                                           N_way=N_WAY,\n",
    "                                           K_shot=K_SHOT,\n",
    "                                           batch_size=16)\n",
    "train_protomaml_loader = data.DataLoader(train_set, \n",
    "                                         batch_sampler=train_protomaml_sampler,\n",
    "                                         collate_fn=train_protomaml_sampler.get_collate_fn(),\n",
    "                                         num_workers=32)\n",
    "\n",
    "# Validation set\n",
    "val_protomaml_sampler = TaskBatchSampler(val_set.targets, \n",
    "                                         include_query=True,\n",
    "                                         N_way=N_WAY,\n",
    "                                         K_shot=K_SHOT,\n",
    "                                         batch_size=1,  # We do not update the parameters, hence the batch size is irrelevant here\n",
    "                                         shuffle=False)\n",
    "val_protomaml_loader = data.DataLoader(val_set, \n",
    "                                       batch_sampler=val_protomaml_sampler,\n",
    "                                       collate_fn=val_protomaml_sampler.get_collate_fn(),\n",
    "                                       num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21799)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_protomaml_sampler.batch_sampler.indices_per_class[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | DCCA_AM | 90.4 K\n",
      "----------------------------------\n",
      "90.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.4 K    Total params\n",
      "0.362     Total estimated model params size (MB)\n",
      "/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:136: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 6.\nOriginal Traceback (most recent call last):\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_1062653/2851881576.py\", line 10, in __getitem__\n    features, targets = self.features[idx], self.targets[idx]\nIndexError: index 139675028265296 is out of bounds for dimension 0 with size 21876\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m   protomaml_model \u001b[39m=\u001b[39m ProtoMAML\u001b[39m.\u001b[39mload_from_checkpoint(model_ckpt_path)\n\u001b[1;32m     11\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 12\u001b[0m   protomaml_model \u001b[39m=\u001b[39m train_model(ProtoMAML, \n\u001b[1;32m     13\u001b[0m                                 lr\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m, \n\u001b[1;32m     14\u001b[0m                                 lr_inner\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     15\u001b[0m                                 lr_output\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m                                 num_inner_steps\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m                                 model_args \u001b[39m=\u001b[39;49m (EEG_INPUT_DIM, EYE_INPUT_DIM, LAYER_SIZES,\n\u001b[1;32m     18\u001b[0m                                   LAYER_SIZES, OUTPUT_DIM, NUM_EMOTIONS, device),\n\u001b[1;32m     19\u001b[0m                                 train_loader\u001b[39m=\u001b[39;49mtrain_protomaml_loader, \n\u001b[1;32m     20\u001b[0m                                 val_loader\u001b[39m=\u001b[39;49mval_protomaml_loader)\n",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model_class, train_loader, val_loader, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     pl\u001b[39m.\u001b[39mseed_everything(\u001b[39m42\u001b[39m)  \u001b[39m# To be reproducable\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     model \u001b[39m=\u001b[39m model_class(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 22\u001b[0m     trainer\u001b[39m.\u001b[39;49mfit(model, train_loader, val_loader)\n\u001b[1;32m     23\u001b[0m     model \u001b[39m=\u001b[39m model_class\u001b[39m.\u001b[39mload_from_checkpoint(\n\u001b[1;32m     24\u001b[0m         trainer\u001b[39m.\u001b[39mcheckpoint_callback\u001b[39m.\u001b[39mbest_model_path)  \u001b[39m# Load best checkpoint after training\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:582\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 582\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    584\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:624\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    617\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    619\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    620\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    622\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    623\u001b[0m )\n\u001b[0;32m--> 624\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    626\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1061\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1059\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1061\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1063\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1140\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1163\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1162\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1163\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:188\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    187\u001b[0m     batch_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 188\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     batch_idx, batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetching_function()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:265\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    263\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_iter)\n\u001b[1;32m    266\u001b[0m         \u001b[39m# consume the batch we just fetched\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:280\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    278\u001b[0m start_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_fetch_start()\n\u001b[1;32m    279\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m    281\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_profiler()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py:568\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    563\u001b[0m     \u001b[39m\"\"\"Fetches the next batch from multiple data loaders.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \n\u001b[1;32m    565\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m        a collections of batch data\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader_iters)\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py:580\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.request_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_next_batch\u001b[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    572\u001b[0m     \u001b[39m\"\"\"Return the batch of data from multiple iterators.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39m        Any: a collections of batch data\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mreturn\u001b[39;00m apply_to_collection(loader_iters, Iterator, \u001b[39mnext\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py:47\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m# Breaking condition\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, dtype) \u001b[39mand\u001b[39;00m (wrong_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[0;32m---> 47\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     49\u001b[0m elem_type \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)\n\u001b[1;32m     51\u001b[0m \u001b[39m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1313\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx]) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   1312\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info\u001b[39m.\u001b[39mpop(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_rcvd_idx)[\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1316\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_data()\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1360\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 6.\nOriginal Traceback (most recent call last):\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_1062653/2851881576.py\", line 10, in __getitem__\n    features, targets = self.features[idx], self.targets[idx]\nIndexError: index 139675028265296 is out of bounds for dimension 0 with size 21876\n"
     ]
    }
   ],
   "source": [
    "EEG_INPUT_DIM = 310\n",
    "EYE_INPUT_DIM = 33\n",
    "OUTPUT_DIM = 12\n",
    "LAYER_SIZES = [200, 50, OUTPUT_DIM]\n",
    "NUM_EMOTIONS = N_WAY\n",
    "\n",
    "model_ckpt_path = os.path.join(os.curdir, \"saved_models\", \"seed-v\", \"protomaml_model.ckpt\")\n",
    "\n",
    "if os.path.exists(model_ckpt_path):\n",
    "  protomaml_model = ProtoMAML.load_from_checkpoint(model_ckpt_path)\n",
    "else:\n",
    "  protomaml_model = train_model(ProtoMAML, \n",
    "                                lr=1e-3, \n",
    "                                lr_inner=0.1,\n",
    "                                lr_output=0.1,\n",
    "                                num_inner_steps=1,\n",
    "                                model_args = (EEG_INPUT_DIM, EYE_INPUT_DIM, LAYER_SIZES,\n",
    "                                  LAYER_SIZES, OUTPUT_DIM, NUM_EMOTIONS, device),\n",
    "                                train_loader=train_protomaml_loader, \n",
    "                                val_loader=val_protomaml_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7c090cfb1e0ab01\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7c090cfb1e0ab01\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Opens tensorboard in notebook. Adjust the path to your CHECKPOINT_PATH if needed\n",
    "%tensorboard --logdir saved_models/seed-v/ProtoMAML/lightning_logs/version_12"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test meta learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase number of inner steps, if necessary, for further improvement in testing phase\n",
    "protomaml_model.hparams.num_inner_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k=5: 45.72% (+-12.21%)\n",
      "Accuracy for k=10: 44.60% (+-8.27%)\n",
      "Accuracy for k=15: 45.63% (+-8.79%)\n"
     ]
    }
   ],
   "source": [
    "protomaml_result_file = os.path.join(CHECKPOINT_PATH, \"protomaml_fewshot.json\")\n",
    "\n",
    "if os.path.isfile(protomaml_result_file):\n",
    "    # Load pre-computed results\n",
    "    with open(protomaml_result_file, 'r') as f:\n",
    "        protomaml_accuracies = json.load(f)\n",
    "    protomaml_accuracies = {int(k): v for k, v in protomaml_accuracies.items()}\n",
    "else:\n",
    "    # Perform same experiments as for ProtoNet\n",
    "    protomaml_accuracies = dict()\n",
    "    for k in [5, 10, 15]:\n",
    "        protomaml_accuracies[k] = test_protomaml(protomaml_model, test_set, k_shot=k)\n",
    "    # Export results\n",
    "    with open(protomaml_result_file, 'w') as f:\n",
    "        json.dump(protomaml_accuracies, f, indent=4)\n",
    "\n",
    "for k in protomaml_accuracies:\n",
    "    print(f\"Accuracy for k={k}: {100.0*protomaml_accuracies[k][0]:4.2f}% (+-{100.0*protomaml_accuracies[k][1]:4.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_few_shot(acc_dict, name, color=None, ax=None):\n",
    "    sns.set()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,3))\n",
    "    ks = sorted(list(acc_dict.keys()))\n",
    "    mean_accs = [acc_dict[k][0] for k in ks]\n",
    "    std_accs = [acc_dict[k][1] for k in ks]\n",
    "    ax.plot(ks, mean_accs, marker='o', markeredgecolor='k', markersize=6, label=name, color=color)\n",
    "    ax.fill_between(ks, [m-s for m,s in zip(mean_accs, std_accs)], [m+s for m,s in zip(mean_accs, std_accs)], alpha=0.2, color=color)\n",
    "    ax.set_xticks(ks)\n",
    "    ax.set_xlim([ks[0]-1, ks[-1]+1])\n",
    "    ax.set_xlabel(\"Number of shots per class\", weight='bold')\n",
    "    ax.set_ylabel(\"Accuracy\", weight='bold')\n",
    "    if len(ax.get_title()) == 0:\n",
    "        ax.set_title(\"Few-Shot Performance \" + name, weight='bold')\n",
    "    else:\n",
    "        ax.set_title(ax.get_title() + \" and \" + name, weight='bold')\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_few_shot(protomaml_accuracies, name=\"ProtoMAML\", color=\"C2\", ax=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83b048a4a9a416379dda64ba975036e59ac92f59ee1596a9a7690ce4fc4021dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

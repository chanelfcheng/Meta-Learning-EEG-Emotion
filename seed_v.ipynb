{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from statistics import mean, stdev\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "torch.manual_seed(0) # Set seed for pytorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR100, SVHN\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "pl.seed_everything(42) # Set seed for pytorch lightning\n",
    "\n",
    "# Import tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set folder paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"raw_data/seed-v/merged_data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"saved_models/seed-v\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset class for SEEDV and initialize a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEEDV(data.Dataset):\n",
    "    def __init__(self, emotion_dict, num_participants, data_dir):\n",
    "        self.emotion_dict = emotion_dict\n",
    "        self.num_participants = num_participants\n",
    "        self.data_dir = data_dir\n",
    "        self.tensor_dataset = self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        dataset = None           \n",
    "        for file in os.listdir(self.data_dir):\n",
    "            file_path = os.path.join(self.data_dir, file)\n",
    "            if dataset is None:\n",
    "                target = np.int64(re.findall(\"\\d+\", file)[0])\n",
    "                for i in range(1, len(np.load(file_path))):\n",
    "                    target = np.hstack((target, int(re.findall(\"\\d+\", file)[0])))\n",
    "                dataset = np.load(file_path)\n",
    "            else:\n",
    "                for i in range(len(np.load(file_path))):\n",
    "                    target = np.hstack((target, np.int64(re.findall(\"\\d+\", file)[0])))\n",
    "                dataset = np.vstack((dataset, np.load(file_path)))\n",
    "\n",
    "        tensor_dataset = data.TensorDataset(torch.from_numpy(dataset[:, :-1]), torch.from_numpy(dataset[:, -1]), torch.from_numpy(target))\n",
    "                    \n",
    "        return tensor_dataset\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        \"\"\"\n",
    "        same as self.__getitem__(self, idx) but instead of a specific index\n",
    "        this function will return all the tuple that contains all features and \n",
    "        combined labels \n",
    "        \"\"\"\n",
    "        all_features = None\n",
    "        all_combined_targets = None\n",
    "\n",
    "        for idx in range(len(self.tensor_dataset)):\n",
    "            if all_features == None:\n",
    "                all_features, all_combined_targets = self.__getitem__(idx)\n",
    "            else:\n",
    "                features, combined_targets = self.__getitem__(idx)\n",
    "                all_features = torch.vstack((all_features, features))\n",
    "                all_combined_targets = torch.vstack((all_combined_targets, combined_targets))\n",
    "        \n",
    "        return all_features, all_combined_targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        return a tuple of features, combined_label (from participant and emotion)\n",
    "        p1: 0 1 2 3 4,\n",
    "        p2: 5 6 7 8 9,\n",
    "        ...\n",
    "        p16: 75 76 77 78 79\n",
    "\n",
    "        we are only given participant # and emotion #\n",
    "        p1_0: 0 = (1 - 1) * 5\n",
    "        p1_1: 1 = 0 + 1\n",
    "        p1_2: 2 = 0 + 2\n",
    "        p1_3: 3 = 0 + 3\n",
    "        p1_4: 4 = 0 + 4\n",
    "        p2_0: 5 = (2 - 1) * 5\n",
    "        p2_1: 6 = 5 + 1\n",
    "        p2_2: 7 = 5 + 2\n",
    "        p2_3: 8 = 5 + 3\n",
    "        p2_4: 9 = 5 + 4\n",
    "        ..\n",
    "        p16_0: 75 = (16 - 1) * 5 = 75\n",
    "        ...\n",
    "        \"\"\"\n",
    "        features = self.tensor_dataset[idx][0]\n",
    "        emotion_num = self.tensor_dataset[idx][1]\n",
    "        participant_num = self.tensor_dataset[idx][2]\n",
    "        base = (participant_num - 1) * len(self.emotion_dict)\n",
    "        combined_target = base + emotion_num\n",
    "\n",
    "        return features, combined_target.to(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_v = SEEDV(emotion_dict = {0: 'disgust', 1: 'fear', 2: 'sad', 3: 'neutral', 4: 'happy'}, num_participants=16, data_dir=DATASET_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a train-val-test split by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = torch.randperm(5*16) # Generate random permutation of numbers from 0 to 79\n",
    "train_classes, val_classes, test_classes = classes[:64], classes[64:72], classes[72:] # 80-10-10 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEEDV_all_features, SEEDV_all_targets = seed_v.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(data.Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features, targets = self.features[idx], self.targets[idx]\n",
    "\n",
    "        return features, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_from_labels(features, targets, class_set): \n",
    "    # for label in labels:\n",
    "    #     print(label)\n",
    "    class_mask = (targets[:,None] == class_set[None,:]).any(dim=-1) # reshape class mask [[64], [64],... ] -> [64, 64, ...]\n",
    "    return EEGDataset(features[class_mask], targets[class_mask]) # reshape labels [[0], [1], ...] -> [0, 1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = dataset_from_labels(\n",
    "    SEEDV_all_features, SEEDV_all_targets.reshape((1,-1))[0], train_classes)\n",
    "val_set = dataset_from_labels(\n",
    "    SEEDV_all_features, SEEDV_all_targets.reshape((1,-1))[0], val_classes)\n",
    "test_set = dataset_from_labels(\n",
    "    SEEDV_all_features, SEEDV_all_targets.reshape((1,-1))[0], test_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataloaders and samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotBatchSampler(object):\n",
    "\n",
    "    def __init__(self, dataset_targets, N_way, K_shot, include_query=False, shuffle=True, shuffle_once=False):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            dataset_targets - PyTorch tensor of the labels of the data elements.\n",
    "            N_way - Number of classes to sample per batch.\n",
    "            K_shot - Number of examples to sample per class in the batch.\n",
    "            include_query - If True, returns batch of size N_way*K_shot*2, which \n",
    "                            can be split into support and query set. Simplifies\n",
    "                            the implementation of sampling the same classes but \n",
    "                            distinct examples for support and query set.\n",
    "            shuffle - If True, examples and classes are newly shuffled in each\n",
    "                      iteration (for training)\n",
    "            shuffle_once - If True, examples and classes are shuffled once in \n",
    "                           the beginning, but kept constant across iterations \n",
    "                           (for validation)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dataset_targets = dataset_targets\n",
    "        self.N_way = N_way\n",
    "        self.K_shot = K_shot\n",
    "        self.shuffle = shuffle\n",
    "        self.include_query = include_query\n",
    "        if self.include_query:\n",
    "            self.K_shot *= 2\n",
    "        self.batch_size = self.N_way * self.K_shot  # Number of overall images per batch\n",
    "\n",
    "        # Organize examples by class\n",
    "        self.classes = torch.unique(self.dataset_targets).tolist()\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.indices_per_class = {}\n",
    "        self.batches_per_class = {}  # Number of K-shot batches that each class can provide\n",
    "        for c in self.classes:\n",
    "            self.indices_per_class[c] = torch.where(self.dataset_targets == c)[0]\n",
    "            self.batches_per_class[c] = self.indices_per_class[c].shape[0] // self.K_shot\n",
    "\n",
    "        # Create a list of classes from which we select the N classes per batch\n",
    "        self.iterations = sum(self.batches_per_class.values()) // self.N_way\n",
    "        self.class_list = [c for c in self.classes for _ in range(self.batches_per_class[c])]\n",
    "        if shuffle_once or self.shuffle:\n",
    "            self.shuffle_data()\n",
    "        else:\n",
    "            # For testing, we iterate over classes instead of shuffling them\n",
    "            sort_idxs = [i+p*self.num_classes for i,\n",
    "                         c in enumerate(self.classes) for p in range(self.batches_per_class[c])]\n",
    "            self.class_list = np.array(self.class_list)[np.argsort(sort_idxs)].tolist()\n",
    "\n",
    "    def shuffle_data(self):\n",
    "        # Shuffle the examples per class\n",
    "        for c in self.classes:\n",
    "            perm = torch.randperm(self.indices_per_class[c].shape[0])\n",
    "            self.indices_per_class[c] = self.indices_per_class[c][perm]\n",
    "        # Shuffle the class list from which we sample. Note that this way of shuffling\n",
    "        # does not prevent to choose the same class twice in a batch. However, for \n",
    "        # training and validation, this is not a problem.\n",
    "        random.shuffle(self.class_list)\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Shuffle data\n",
    "        if self.shuffle:\n",
    "            self.shuffle_data()\n",
    "\n",
    "        # Sample few-shot batches\n",
    "        start_index = defaultdict(int)\n",
    "        for it in range(self.iterations):\n",
    "            # Select N classes for the batch\n",
    "            class_batch = self.class_list[it*self.N_way:(it+1)*self.N_way]\n",
    "            index_batch = []\n",
    "            for c in class_batch:  # For each class, select the next K examples and add them to the batch\n",
    "                index_batch.extend(self.indices_per_class[c][start_index[c]:start_index[c]+self.K_shot])\n",
    "                start_index[c] += self.K_shot\n",
    "                try:\n",
    "                    self.indices_per_class[c][start_index[c]]\n",
    "                except:\n",
    "                    start_index[c] = 0\n",
    "            if self.include_query:  # If we return support+query set, sort them so that they are easy to split\n",
    "                index_batch = index_batch[::2] + index_batch[1::2]\n",
    "            yield index_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WAY = 2\n",
    "K_SHOT = 10\n",
    "train_data_loader = data.DataLoader(train_set,\n",
    "                                    batch_sampler=FewShotBatchSampler(train_set.targets,\n",
    "                                                                      include_query=True,\n",
    "                                                                      N_way=N_WAY,\n",
    "                                                                      K_shot=K_SHOT,\n",
    "                                                                      shuffle=True),\n",
    "                                    num_workers=32)\n",
    "val_data_loader = data.DataLoader(val_set,\n",
    "                                  batch_sampler=FewShotBatchSampler(val_set.targets,\n",
    "                                                                    include_query=True,\n",
    "                                                                    N_way=N_WAY,\n",
    "                                                                    K_shot=K_SHOT,\n",
    "                                                                    shuffle=False,\n",
    "                                                                    shuffle_once=True),\n",
    "                                  num_workers=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split batch into query and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_query_support(features, targets):\n",
    "    support_features, query_features = features.chunk(2, dim=0)\n",
    "    support_targets, query_targets = targets.chunk(2, dim=0)\n",
    "    return support_features, query_features, support_targets, query_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, targets = next(iter(val_data_loader))\n",
    "support_features, query_features, support_targets, query_targets = split_query_support(features, targets)\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "# ax[0].plot(support_features, 'o')\n",
    "# ax[0].set_title(\"Support set\")\n",
    "# ax[0].axis('off')\n",
    "# ax[1].plot(query_features, 'o')\n",
    "# ax[1].set_title(\"Query set\")\n",
    "# ax[1].axis('off')\n",
    "# plt.suptitle(\"Few Shot Batch\", weight='bold')\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize and visualize the features in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "support_features = support_features / support_features.max(0, keepdim=True)[0]\n",
    "query_features = query_features / query_features.max(0, keepdim=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "support_pca = pca.fit_transform(support_features)\n",
    "query_pca = pca.fit_transform(query_features)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "ax[0].scatter(support_pca[:,0], support_pca[:,1], c=support_targets)\n",
    "ax[0].set_title(\"Support set\")\n",
    "ax[0].axis('off')\n",
    "ax[1].scatter(query_pca[:,0], query_pca[:,1], c=query_targets)\n",
    "ax[1].set_title(\"Query set\")\n",
    "ax[1].axis('off')\n",
    "plt.suptitle(\"Few Shot Batch\", weight='bold')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DCCA neural network used in SEEDV paper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define CCA methods and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cca_metric_derivative(H1, H2):\n",
    "    r1 = 1e-3\n",
    "    r2 = 1e-3\n",
    "    eps = 1e-9\n",
    "    # transform the matrix: to be consistent with the original paper\n",
    "    H1 = H1.T\n",
    "    H2 = H2.T\n",
    "    # o1 and o2 are feature dimensions\n",
    "    # m is sample number\n",
    "    o1 = o2 = H1.shape[0]\n",
    "    m = H1.shape[1]\n",
    "\n",
    "    # calculate parameters\n",
    "    H1bar = H1 - H1.mean(axis=1).reshape([-1,1])\n",
    "    H2bar = H2 - H2.mean(axis=1).reshape([-1,1])\n",
    "\n",
    "    SigmaHat12 = (1.0 / (m - 1)) * np.matmul(H1bar, H2bar.T)\n",
    "    SigmaHat11 = (1.0 / (m - 1)) * np.matmul(H1bar, H1bar.T) + r1 * np.eye(o1)\n",
    "    SigmaHat22 = (1.0 / (m - 1)) * np.matmul(H2bar, H2bar.T) + r2 * np.eye(o2)\n",
    "\n",
    "    # eigenvalue and eigenvector decomposition\n",
    "    [D1, V1] = np.linalg.eigh(SigmaHat11)\n",
    "    [D2, V2] = np.linalg.eigh(SigmaHat22)\n",
    "\n",
    "    # remove eighvalues and eigenvectors smaller than 0\n",
    "    posInd1 = np.where(D1 > 0)[0]\n",
    "    D1 = D1[posInd1]\n",
    "    V1 = V1[:, posInd1]\n",
    "\n",
    "    posInd2 = np.where(D2 > 0)[0]\n",
    "    D2 = D2[posInd2]\n",
    "    V2 = V2[:, posInd2]\n",
    "\n",
    "    # calculate matrxi T\n",
    "    SigmaHat11RootInv = np.matmul(np.matmul(V1, np.diag(D1 ** -0.5)), V1.T)\n",
    "    SigmaHat22RootInv = np.matmul(np.matmul(V2, np.diag(D2 ** -0.5)), V2.T)\n",
    "    Tval = np.matmul(np.matmul(SigmaHat11RootInv,SigmaHat12), SigmaHat22RootInv)\n",
    "    # By default, we will use all the singular values\n",
    "    tmp = np.matmul(Tval.T, Tval)\n",
    "    corr = np.sqrt(np.trace(tmp))\n",
    "    cca_loss = -1 * corr\n",
    "\n",
    "    # calculate the derivative of H1 and H2\n",
    "    U_t, D_t, V_prime_t = np.linalg.svd(Tval)\n",
    "    Delta12 = SigmaHat11RootInv @ U_t @ V_prime_t @ SigmaHat22RootInv\n",
    "    Delta11 = SigmaHat11RootInv @ U_t @ np.diag(D_t) @ U_t.T @ SigmaHat11RootInv\n",
    "    Delta22 = SigmaHat22RootInv @ U_t @ np.diag(D_t) @ U_t.T @ SigmaHat22RootInv\n",
    "    Delta11 = -0.5 * Delta11\n",
    "    Delta22 = -0.5 * Delta22\n",
    "\n",
    "    DerivativeH1 = ( 1.0 / (m - 1)) * (2 * (Delta11 @ H1bar) + Delta12 @ H2bar)\n",
    "    DerivativeH2 = ( 1.0 / (m - 1)) * (2 * (Delta22 @ H2bar) + Delta12 @ H1bar)\n",
    "\n",
    "    return cca_loss, DerivativeH1.T, DerivativeH2.T\n",
    "\n",
    "class cca_loss():\n",
    "    def __init__(self, outdim_size, use_all_singular_values, device):\n",
    "        self.outdim_size = outdim_size\n",
    "        self.use_all_singular_values = use_all_singular_values\n",
    "        self.device = device\n",
    "\n",
    "    def loss(self, H1, H2):\n",
    "        r1 = 1e-3\n",
    "        r2 = 1e-3\n",
    "        eps = 1e-9\n",
    "\n",
    "        H1, H2 = H1.t(), H2.t()\n",
    "        o1 = o2 = H1.size(0)\n",
    "\n",
    "        m = H1.size(1)\n",
    "\n",
    "        H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)\n",
    "        H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)\n",
    "\n",
    "        SigmaHat12 = (1.0 / (m - 1)) * torch.matmul(H1bar, H2bar.t())\n",
    "        SigmaHat11 = (1.0 / (m - 1)) * torch.matmul(H1bar,\n",
    "                                                    H1bar.t()) + r1 * torch.eye(o1, device=self.device)\n",
    "        SigmaHat22 = (1.0 / (m - 1)) * torch.matmul(H2bar,\n",
    "                                                    H2bar.t()) + r2 * torch.eye(o2, device=self.device)\n",
    "\n",
    "        # Calculating the root inverse of covariance matrices by using eigen decomposition\n",
    "        breakpoint()\n",
    "        [D1, V1] = torch.symeig(SigmaHat11, eigenvectors=True)\n",
    "        [D2, V2] = torch.symeig(SigmaHat22, eigenvectors=True)\n",
    "\n",
    "        # Added to increase stability\n",
    "        posInd1 = torch.gt(D1, eps).nonzero()[:, 0]\n",
    "        D1 = D1[posInd1]\n",
    "        V1 = V1[:, posInd1]\n",
    "        posInd2 = torch.gt(D2, eps).nonzero()[:, 0]\n",
    "        D2 = D2[posInd2]\n",
    "        V2 = V2[:, posInd2]\n",
    "\n",
    "        SigmaHat11RootInv = torch.matmul(\n",
    "            torch.matmul(V1, torch.diag(D1 ** -0.5)), V1.t())\n",
    "        SigmaHat22RootInv = torch.matmul(\n",
    "            torch.matmul(V2, torch.diag(D2 ** -0.5)), V2.t())\n",
    "\n",
    "        Tval = torch.matmul(torch.matmul(SigmaHat11RootInv,\n",
    "                                         SigmaHat12), SigmaHat22RootInv)\n",
    "\n",
    "        if self.use_all_singular_values:\n",
    "            # all singular values are used to calculate the correlation\n",
    "            tmp = torch.matmul(Tval.t(), Tval)\n",
    "            corr = torch.trace(torch.sqrt(tmp))\n",
    "            # assert torch.isnan(corr).item() == 0\n",
    "        else:\n",
    "            # just the top self.outdim_size singular values are used\n",
    "            trace_TT = torch.matmul(Tval.t(), Tval)\n",
    "            trace_TT = torch.add(trace_TT, (torch.eye(trace_TT.shape[0])*r1).to(self.device)) # regularization for more stability\n",
    "            U, V = torch.symeig(trace_TT, eigenvectors=True)\n",
    "            U = torch.where(U>eps, U, (torch.ones(U.shape)*eps).to(self.device))\n",
    "            U = U.topk(self.outdim_size)[0]\n",
    "            corr = torch.sum(torch.sqrt(U))\n",
    "        return -corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define DCCA network layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformLayers(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes):\n",
    "        super(TransformLayers, self).__init__()\n",
    "        layers = []\n",
    "        layer_sizes = [input_size] + layer_sizes\n",
    "        for l_id in range(len(layer_sizes) - 1):\n",
    "            if l_id == len(layer_sizes) - 2:\n",
    "                layers.append(nn.Sequential(\n",
    "                    #nn.BatchNorm1d(num_features=layer_sizes[l_id], affine=False),\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id+1]),\n",
    "                    ))\n",
    "            else:\n",
    "                layers.append(nn.Sequential(\n",
    "                    nn.Linear(layer_sizes[l_id], layer_sizes[l_id+1]),\n",
    "                    nn.Sigmoid(),\n",
    "                    #nn.BatchNorm1d(num_features=layer_sizes[l_id+1], affine=False),\n",
    "                    ))\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class AttentionFusion(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super(AttentionFusion, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.attention_weights = nn.Parameter(torch.randn(self.output_dim, requires_grad=True))\n",
    "    def forward(self, x1, x2):\n",
    "        # calculate weigths for all input samples\n",
    "        row, _ = x1.shape\n",
    "        fused_tensor = torch.empty_like(x1)\n",
    "        alpha = []\n",
    "        for i in range(row):\n",
    "            tmp1 = torch.dot(x1[i,:], self.attention_weights)\n",
    "            tmp2 = torch.dot(x2[i,:], self.attention_weights)\n",
    "            alpha_1 = torch.exp(tmp1) / (torch.exp(tmp1) + torch.exp(tmp2))\n",
    "            alpha_2 = 1 - alpha_1\n",
    "            alpha.append((alpha_1.detach().cpu().numpy(), alpha_2.detach().cpu().numpy()))\n",
    "            fused_tensor[i, :] = alpha_1 * x1[i,:] + alpha_2 * x2[i, :]\n",
    "        return fused_tensor, alpha\n",
    "\n",
    "class DCCA_AM(nn.Module):\n",
    "    def __init__(self, input_size1, input_size2, layer_sizes1, layer_sizes2, outdim_size, categories, device):\n",
    "        super(DCCA_AM, self).__init__()\n",
    "        self.input_dim_split = input_size1\n",
    "        self.outdim_size = outdim_size\n",
    "        self.categories = categories\n",
    "        # self.use_all_singular_values = use_all_singular_values\n",
    "        self.device = device\n",
    "\n",
    "        self.model1 = TransformLayers(input_size1, layer_sizes1).to(self.device)\n",
    "        self.model2 = TransformLayers(input_size2, layer_sizes2).to(self.device)\n",
    "\n",
    "        # convert generator object to list for deepcopy(model) to work\n",
    "        self.model1_parameters = list(self.model1.parameters()) \n",
    "        self.model2_parameters = list(self.model2.parameters())\n",
    "\n",
    "        self.classification = nn.Linear(self.outdim_size, self.categories)\n",
    "\n",
    "        self.attention_fusion = AttentionFusion(outdim_size)\n",
    "    def forward(self, x):\n",
    "        x1 = x[:, :self.input_dim_split]\n",
    "        x2 = x[:, self.input_dim_split:]\n",
    "        # forward process: returns negative of cca loss and predicted labels\n",
    "        output1 = self.model1(x1)\n",
    "        output2 = self.model2(x2)\n",
    "        # cca_loss_val = self.loss(output1, output2)\n",
    "        cca_loss, partial_h1, partial_h2 = cca_metric_derivative(output1.detach().cpu().numpy(), output2.detach().cpu().numpy())\n",
    "        fused_tensor, alpha = self.attention_fusion(output1, output2)\n",
    "        out = self.classification(fused_tensor)\n",
    "        return out, cca_loss, output1, output2, partial_h1, partial_h2, fused_tensor.detach().cpu().data, alpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define meta learning model and methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define baseline ProtoNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoNet(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, lr, model_args):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            proto_dim - Dimensionality of prototype feature space\n",
    "            lr - Learning rate of Adam optimizer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, \\\n",
    "            output_dim, num_emotions, device = model_args\n",
    "        self.model = DCCA_AM(eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, output_dim, num_emotions, device).to(device)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=[140, 180], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_prototypes(features, targets):\n",
    "        # Given a stack of features vectors and labels, return class prototypes\n",
    "        # features - shape [N, proto_dim], targets - shape [N]\n",
    "        features = features[0]\n",
    "        # targets = targets.reshape((1,-1))[0] \n",
    "        # already RESHAPED EARLIER in dataset_from_labels call\n",
    "        classes, _ = torch.unique(targets).sort() # Determine which classes we have\n",
    "        prototypes = []\n",
    "        # print(\"targets:\", targets)\n",
    "        for c in classes:\n",
    "            # print(\"c:\", c)\n",
    "            # print(features[torch.where(targets == c)[0]])\n",
    "            # maybe use for target in targets loop\n",
    "            p = features[torch.where(targets == c)[0]].mean(dim=0)  # Average class feature vectors\n",
    "            prototypes.append(p)\n",
    "        prototypes = torch.stack(prototypes, dim=0)\n",
    "        # Return the 'classes' tensor to know which prototype belongs to which class\n",
    "        return prototypes, classes\n",
    "\n",
    "    def classify_feats(self, prototypes, classes, feats, targets):\n",
    "        # Classify new examples with prototypes and return classification error\n",
    "        dist = torch.pow(prototypes[None, :] - feats[:, None], 2).sum(dim=2)  # Squared euclidean distance\n",
    "        preds = F.log_softmax(-dist, dim=1)\n",
    "        labels = (classes[None, :] == targets[:, None]).long().argmax(dim=-1)\n",
    "        acc = (preds.argmax(dim=1) == labels).float().mean()\n",
    "        return preds, labels, acc\n",
    "\n",
    "    def calculate_loss(self, batch, mode):\n",
    "        # Determine training loss for a given support and query set \n",
    "        features, targets = batch\n",
    "        outputs = self.model(features)  # Encode all images of support and query set\n",
    "        support_feats, query_feats, support_targets, query_targets = split_query_support(outputs, targets)\n",
    "        prototypes, classes = ProtoNet.calculate_prototypes(support_feats, support_targets)\n",
    "        preds, labels, acc = self.classify_feats(prototypes, classes, query_feats, query_targets)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "        self.log(f\"{mode}_loss\", loss)\n",
    "        self.log(f\"{mode}_acc\", acc)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.calculate_loss(batch, mode=\"train\")\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self.calculate_loss(batch, mode=\"val\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ProtoMAML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProtoMAML(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, lr, lr_inner, lr_output, num_inner_steps, model_args):\n",
    "        \"\"\"\n",
    "        Inputs\n",
    "            eeg_input_dim - Dimensionality of prototype feature space\n",
    "            lr - Learning rate of the outer loop Adam optimizer\n",
    "            lr_inner - Learning rate of the inner loop SGD optimizer\n",
    "            lr_output - Learning rate for the output layer in the inner loop\n",
    "            num_inner_steps - Number of inner loop updates to perform\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, \\\n",
    "            output_dim, num_emotions, device = model_args\n",
    "        self.model = DCCA_AM(eeg_input_dim, eye_input_dim, layer_sizes1, layer_sizes2, output_dim, num_emotions, device).to(device)\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[140,180], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "        \n",
    "    def run_model(self, local_model, output_weight, output_bias, features, target_indices):\n",
    "        # Execute a model with given output layer weights and inputs\n",
    "        dcca_out = local_model(features)\n",
    "        out = dcca_out[0]\n",
    "        cca_loss = dcca_out[1]\n",
    "        preds = F.linear(out, output_weight, output_bias)\n",
    "        # loss = F.cross_entropy(preds, labels.reshape((-1,1))[0]) \n",
    "        # already RESHAPED EARLIER in dataset_from_labels calls\n",
    "        loss = 0.7 * cca_loss + 1.0 * F.cross_entropy(preds, target_indices)\n",
    "        acc = (preds.argmax(dim=1) == target_indices).float()\n",
    "        return loss, preds, acc\n",
    "        \n",
    "    def adapt_few_shot(self, support_features, support_targets):\n",
    "        # Determine prototype initialization\n",
    "        support_feats = self.model(support_features)\n",
    "        prototypes, classes = ProtoNet.calculate_prototypes(support_feats, support_targets)\n",
    "        support_labels = (classes[None,:] == support_targets[:,None]).long().argmax(dim=-1)\n",
    "        # Create inner-loop model and optimizer\n",
    "        local_model = deepcopy(self.model)\n",
    "        local_model.train()\n",
    "        local_optim = optim.SGD(local_model.parameters(), lr=self.hparams.lr_inner)\n",
    "        local_optim.zero_grad()\n",
    "        # Create output layer weights with prototype-based initialization\n",
    "        init_weight = 2 * prototypes\n",
    "        init_bias = -torch.norm(prototypes, dim=1)**2\n",
    "        output_weight = init_weight.detach().requires_grad_()\n",
    "        output_bias = init_bias.detach().requires_grad_()\n",
    "        \n",
    "        # Optimize inner loop model on support set\n",
    "        for _ in range(self.hparams.num_inner_steps):\n",
    "            # Determine loss on the support set\n",
    "            loss, _, _ = self.run_model(local_model, output_weight, output_bias, support_features, support_labels)\n",
    "            # Calculate gradients and perform inner loop update\n",
    "            loss.backward()\n",
    "            local_optim.step()\n",
    "            # Update output layer via SGD\n",
    "            output_weight.data -= self.hparams.lr_output * output_weight.grad\n",
    "            output_bias.data -= self.hparams.lr_output * output_bias.grad\n",
    "            # Reset gradients\n",
    "            local_optim.zero_grad()\n",
    "            output_weight.grad.fill_(0)\n",
    "            output_bias.grad.fill_(0)\n",
    "            \n",
    "        # Re-attach computation graph of prototypes\n",
    "        output_weight = (output_weight - init_weight).detach() + init_weight\n",
    "        output_bias = (output_bias - init_bias).detach() + init_bias\n",
    "        \n",
    "        return local_model, output_weight, output_bias, classes\n",
    "        \n",
    "    def outer_loop(self, batch, mode=\"train\"):\n",
    "        accuracies = []\n",
    "        losses = []\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Determine gradients for batch of tasks\n",
    "        for task_batch in batch:\n",
    "            features, targets = task_batch\n",
    "            support_features, query_features, support_targets, query_targets = split_query_support(features, targets)\n",
    "            # Perform inner loop adaptation\n",
    "            local_model, output_weight, output_bias, classes = self.adapt_few_shot(support_features, support_targets)\n",
    "            # Determine loss of query set\n",
    "            query_labels = (classes[None,:] == query_targets[:,None]).long().argmax(dim=-1)\n",
    "            loss, preds, acc = self.run_model(local_model, output_weight, output_bias, query_features, query_labels)\n",
    "            # Calculate gradients for query set loss\n",
    "            if mode == \"train\":\n",
    "                loss.backward()\n",
    "\n",
    "                for p_global, p_local in zip(self.model.parameters(), local_model.parameters()):\n",
    "                    p_global.grad += p_local.grad  # First-order approx. -> add gradients of finetuned and base model\n",
    "            \n",
    "            accuracies.append(acc.mean().detach())\n",
    "            losses.append(loss.detach())\n",
    "        \n",
    "        # Perform update of base model\n",
    "        if mode == \"train\":\n",
    "            opt = self.optimizers()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        self.log(f\"{mode}_loss\", sum(losses) / len(losses))\n",
    "        self.log(f\"{mode}_acc\", sum(accuracies) / len(accuracies))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        self.outer_loop(batch, mode=\"train\")\n",
    "        return None  # Returning None means we skip the default training optimizer steps by PyTorch Lightning\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # Validation requires to finetune a model, hence we need to enable gradients\n",
    "        torch.set_grad_enabled(True)\n",
    "        self.outer_loop(batch, mode=\"val\")\n",
    "        torch.set_grad_enabled(False)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # Testing requires to finetune a model, hence we need to enable gradients\n",
    "        torch.set_grad_enabled(True)\n",
    "        self.outer_loop(batch, mode=\"test\")\n",
    "        torch.set_grad_enabled(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define task batch sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskBatchSampler(object):\n",
    "    \n",
    "    def __init__(self, dataset_targets, batch_size, N_way, K_shot, include_query=False, shuffle=True):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            dataset_targets - PyTorch tensor of the labels of the data elements.\n",
    "            batch_size - Number of tasks to aggregate in a batch\n",
    "            N_way - Number of classes to sample per batch.\n",
    "            K_shot - Number of examples to sample per class in the batch.\n",
    "            include_query - If True, returns batch of size N_way*K_shot*2, which \n",
    "                            can be split into support and query set. Simplifies\n",
    "                            the implementation of sampling the same classes but \n",
    "                            distinct examples for support and query set.\n",
    "            shuffle - If True, examples and classes are newly shuffled in each\n",
    "                      iteration (for training)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.batch_sampler = FewShotBatchSampler(dataset_targets, N_way, K_shot, include_query, shuffle)\n",
    "        self.task_batch_size = batch_size\n",
    "        self.local_batch_size = self.batch_sampler.batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # Aggregate multiple batches before returning the indices\n",
    "        batch_list = []\n",
    "        for batch_idx, batch in enumerate(self.batch_sampler):\n",
    "            batch_list.extend(batch)\n",
    "            if (batch_idx+1) % self.task_batch_size == 0:\n",
    "                yield batch_list\n",
    "                batch_list = []\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)//self.task_batch_size\n",
    "    \n",
    "    def get_collate_fn(self):\n",
    "        # Returns a collate function that converts one big tensor into a list of task-specific tensors\n",
    "        def collate_fn(item_list):\n",
    "            features = torch.stack([feat for feat, target in item_list], dim=0)\n",
    "            targets = torch.stack([target for feat, target in item_list], dim=0)\n",
    "            features = features.chunk(self.task_batch_size, dim=0)\n",
    "            targets = targets.chunk(self.task_batch_size, dim=0)\n",
    "            return list(zip(features, targets))\n",
    "        return collate_fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train meta learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_class, train_loader, val_loader, **kwargs):\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, model_class.__name__),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=30,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"min\", monitor=\"val_loss\", every_n_epochs=1),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         enable_progress_bar=False,\n",
    "                         log_every_n_steps=10)\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(\n",
    "        CHECKPOINT_PATH, model_class.__name__ + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        # Automatically loads the model with the saved hyperparameters\n",
    "        model = model_class.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducable\n",
    "        model = model_class(**kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = model_class.load_from_checkpoint(\n",
    "            trainer.checkpoint_callback.best_model_path)  # Load best checkpoint after training\n",
    "\n",
    "    return model, trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training constant (same as for ProtoNet)\n",
    "N_WAY = 2\n",
    "K_SHOT = 10\n",
    "\n",
    "# Training set\n",
    "train_protomaml_sampler = TaskBatchSampler(train_set.targets, \n",
    "                                           include_query=True,\n",
    "                                           N_way=N_WAY,\n",
    "                                           K_shot=K_SHOT,\n",
    "                                           batch_size=16)\n",
    "train_protomaml_loader = data.DataLoader(train_set, \n",
    "                                         batch_sampler=train_protomaml_sampler,\n",
    "                                         collate_fn=train_protomaml_sampler.get_collate_fn(),\n",
    "                                         num_workers=32)\n",
    "\n",
    "# Validation set\n",
    "val_protomaml_sampler = TaskBatchSampler(val_set.targets, \n",
    "                                         include_query=True,\n",
    "                                         N_way=N_WAY,\n",
    "                                         K_shot=K_SHOT,\n",
    "                                         batch_size=16,  # We do not update the parameters, hence the batch size is irrelevant here\n",
    "                                         shuffle=False)\n",
    "val_protomaml_loader = data.DataLoader(val_set, \n",
    "                                       batch_sampler=val_protomaml_sampler,\n",
    "                                       collate_fn=val_protomaml_sampler.get_collate_fn(),\n",
    "                                       num_workers=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | DCCA_AM | 90.4 K\n",
      "----------------------------------\n",
      "90.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.4 K    Total params\n",
      "0.361     Total estimated model params size (MB)\n",
      "/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py:136: UserWarning: `training_step` returned `None`. If this was on purpose, ignore this warning...\n",
      "  self.warning_cache.warn(\"`training_step` returned `None`. If this was on purpose, ignore this warning...\")\n",
      "/home/chanel/miniconda3/envs/pl-env/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "EEG_INPUT_DIM = 310\n",
    "EYE_INPUT_DIM = 33\n",
    "OUTPUT_DIM = 12\n",
    "LAYER_SIZES = [200, 50, OUTPUT_DIM]\n",
    "NUM_EMOTIONS = N_WAY\n",
    "\n",
    "protomaml_model, trainer = train_model(ProtoMAML, \n",
    "                              lr=1e-3, \n",
    "                              lr_inner=0.1,\n",
    "                              lr_output=0.1,\n",
    "                              num_inner_steps=1,\n",
    "                              model_args = (EEG_INPUT_DIM, EYE_INPUT_DIM, LAYER_SIZES,\n",
    "                                LAYER_SIZES, OUTPUT_DIM, NUM_EMOTIONS, device),\n",
    "                              train_loader=train_protomaml_loader, \n",
    "                              val_loader=val_protomaml_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test meta learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_protomaml(model, trainer, dataset, n_way, k_shot=4):\n",
    "    pl.seed_everything(42)\n",
    "    model = model.to(device)\n",
    "    num_classes = dataset.targets.unique().shape[0]\n",
    "\n",
    "    # Data loader for full test set as query set\n",
    "    full_dataloader = data.DataLoader(dataset, batch_size=128, num_workers=32, shuffle=False, drop_last=False)\n",
    "    # Data loader for sampling support sets\n",
    "    sampler = FewShotBatchSampler(\n",
    "        dataset.targets, include_query=False, N_way=n_way, K_shot=k_shot, shuffle=False, shuffle_once=False\n",
    "    )\n",
    "    sample_dataloader = data.DataLoader(dataset, batch_sampler=sampler, num_workers=32)\n",
    "\n",
    "    # We iterate through the full dataset in two manners. First, to select the k-shot batch.\n",
    "    # Second, the evaluate the model on all other examples\n",
    "    accuracies = []\n",
    "    for (support_imgs, support_targets), support_indices in tqdm(\n",
    "        zip(sample_dataloader, sampler), \"Performing few-shot finetuning\"\n",
    "    ):\n",
    "        support_imgs = support_imgs.to(device)\n",
    "        support_targets = support_targets.to(device)\n",
    "        # Finetune new model on support set\n",
    "        local_model, output_weight, output_bias, classes = model.adapt_few_shot(support_imgs, support_targets)\n",
    "        with torch.no_grad():  # No gradients for query set needed\n",
    "            local_model.eval()\n",
    "            batch_acc = torch.zeros((0,), dtype=torch.float32, device=device)\n",
    "            # Evaluate all examples in test dataset\n",
    "            for query_imgs, query_targets in full_dataloader:\n",
    "                query_imgs = query_imgs.to(device)\n",
    "                query_targets = query_targets.to(device)\n",
    "                query_labels = (classes[None, :] == query_targets[:, None]).long().argmax(dim=-1)\n",
    "                _, _, acc = model.run_model(local_model, output_weight, output_bias, query_imgs, query_labels)\n",
    "                batch_acc = torch.cat([batch_acc, acc.detach()], dim=0)\n",
    "            # Exclude support set elements\n",
    "            for s_idx in support_indices:\n",
    "                batch_acc[s_idx] = 0\n",
    "            batch_acc = batch_acc.sum().item() / (batch_acc.shape[0] - len(support_indices))\n",
    "            accuracies.append(batch_acc)\n",
    "    return mean(accuracies), stdev(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce inner learning rate for few shot and increase number of inner steps, if necessary, for further \n",
    "# improvement during testing phase\n",
    "protomaml_model.hparams.lr_inner = 0.1\n",
    "protomaml_model.hparams.lr_output = 0.1\n",
    "protomaml_model.hparams.num_inner_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protomaml_result_file = os.path.join(CHECKPOINT_PATH, \"protomaml_fewshot.json\")\n",
    "\n",
    "# Perform same experiments as for ProtoNet\n",
    "protomaml_accuracies = dict()\n",
    "for k in [5, 10, 15]:\n",
    "    protomaml_accuracies[k] = test_protomaml(protomaml_model, trainer, test_set, n_way=N_WAY, k_shot=k)\n",
    "    print(f\"Accuracy for k={k}: {100.0*protomaml_accuracies[k][0]:4.2f}% (+-{100.0*protomaml_accuracies[k][1]:4.2f}%)\")\n",
    "# Export results\n",
    "with open(protomaml_result_file, 'w') as f:\n",
    "    json.dump(protomaml_accuracies, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_few_shot(acc_dict, name, color=None, ax=None):\n",
    "    sns.set()\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,3))\n",
    "    ks = sorted(list(acc_dict.keys()))\n",
    "    mean_accs = [acc_dict[k][0] for k in ks]\n",
    "    std_accs = [acc_dict[k][1] for k in ks]\n",
    "    ax.plot(ks, mean_accs, marker='o', markeredgecolor='k', markersize=6, label=name, color=color)\n",
    "    ax.fill_between(ks, [m-s for m,s in zip(mean_accs, std_accs)], [m+s for m,s in zip(mean_accs, std_accs)], alpha=0.2, color=color)\n",
    "    ax.set_xticks(ks)\n",
    "    ax.set_xlim([ks[0]-1, ks[-1]+1])\n",
    "    ax.set_xlabel(\"Number of shots per class\", weight='bold')\n",
    "    ax.set_ylabel(\"Accuracy\", weight='bold')\n",
    "    if len(ax.get_title()) == 0:\n",
    "        ax.set_title(\"Few-Shot Performance \" + name, weight='bold')\n",
    "    else:\n",
    "        ax.set_title(ax.get_title() + \" and \" + name, weight='bold')\n",
    "    ax.legend()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_few_shot(protomaml_accuracies, name=\"ProtoMAML\", color=\"C2\", ax=None)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83b048a4a9a416379dda64ba975036e59ac92f59ee1596a9a7690ce4fc4021dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
